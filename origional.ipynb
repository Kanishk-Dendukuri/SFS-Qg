{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98a98e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (640, 50) (640, 5)\n",
      "Validation set: (80, 50) (80, 5)\n",
      "Test set: (80, 50) (80, 5)\n",
      "Validation MSE for each output: [0.00095248 0.00029309 0.00271742 0.00103777 0.00143985]\n",
      "Overall Validation MSE: 0.0012881226362468185\n",
      "XGBoost Validation MSE: [0.0009246  0.00030657 0.00237065 0.00074768 0.00166186]\n",
      "Overall Validation MSE: 0.0012022716022176694\n",
      "CatBoost Validation MSE: [0.00060637 0.00013584 0.00234464 0.00101009 0.00127334]\n",
      "Overall Validation MSE: 0.0010740552124411714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "data = pd.read_csv('Combined.csv')\n",
    "\n",
    "X = data[[f'Feature_{i+1}' for i in range(50)]]\n",
    "y = data[[f'Output_{i+1}' for i in range(5)]]  # Assuming 5 outputs\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Confirm split sizes\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred, multioutput='raw_values')\n",
    "print(\"Validation MSE for each output:\", val_mse)\n",
    "overall_val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_mse)\n",
    "\n",
    "\n",
    "\n",
    "xgb_model = MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "xgb_val_mse = mean_squared_error(y_val, xgb_val_pred, multioutput='raw_values')\n",
    "\n",
    "print(\"XGBoost Validation MSE:\", xgb_val_mse)\n",
    "overall_val_xgb = mean_squared_error(y_val, xgb_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_xgb)\n",
    "\n",
    "\n",
    "# CatBoost model\n",
    "catboost_model = MultiOutputRegressor(CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1, loss_function='MultiRMSE', random_seed=42, verbose=0))\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_val_pred = catboost_model.predict(X_val)\n",
    "catboost_val_mse = mean_squared_error(y_val, catboost_val_pred, multioutput='raw_values')\n",
    "\n",
    "print(\"CatBoost Validation MSE:\", catboost_val_mse)\n",
    "overall_val_cat = mean_squared_error(y_val, catboost_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821e332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Average_MIC\n",
      "17  Feature_18     0.606275\n",
      "1    Feature_2     0.577277\n",
      "18  Feature_19     0.565833\n",
      "24  Feature_25     0.559473\n",
      "16  Feature_17     0.550203\n",
      "14  Feature_15     0.544664\n",
      "3    Feature_4     0.538556\n",
      "11  Feature_12     0.534757\n",
      "6    Feature_7     0.530309\n",
      "2    Feature_3     0.524645\n",
      "15  Feature_16     0.514047\n",
      "12  Feature_13     0.513364\n",
      "21  Feature_22     0.511601\n",
      "5    Feature_6     0.463500\n",
      "19  Feature_20     0.461163\n",
      "8    Feature_9     0.458065\n",
      "20  Feature_21     0.455153\n",
      "7    Feature_8     0.430996\n",
      "4    Feature_5     0.430190\n",
      "10  Feature_11     0.409021\n",
      "23  Feature_24     0.400841\n",
      "22  Feature_23     0.396367\n",
      "41  Feature_42     0.389559\n",
      "33  Feature_34     0.380219\n",
      "26  Feature_27     0.371027\n",
      "42  Feature_43     0.351353\n",
      "31  Feature_32     0.344761\n",
      "13  Feature_14     0.333625\n",
      "27  Feature_28     0.331494\n",
      "30  Feature_31     0.329151\n",
      "45  Feature_46     0.321862\n",
      "37  Feature_38     0.320492\n",
      "35  Feature_36     0.311074\n",
      "47  Feature_48     0.293028\n",
      "32  Feature_33     0.280682\n",
      "44  Feature_45     0.273185\n",
      "49  Feature_50     0.268011\n",
      "48  Feature_49     0.263064\n",
      "38  Feature_39     0.262400\n",
      "9   Feature_10     0.260143\n",
      "0    Feature_1     0.248457\n",
      "43  Feature_44     0.245200\n",
      "36  Feature_37     0.228262\n",
      "46  Feature_47     0.226284\n",
      "34  Feature_35     0.221410\n",
      "28  Feature_29     0.216448\n",
      "29  Feature_30     0.215401\n",
      "40  Feature_41     0.209255\n",
      "39  Feature_40     0.192317\n",
      "25  Feature_26     0.185156\n",
      "       Feature  Average_MI\n",
      "17  Feature_18    0.826553\n",
      "1    Feature_2    0.743456\n",
      "24  Feature_25    0.710861\n",
      "18  Feature_19    0.690382\n",
      "16  Feature_17    0.667548\n",
      "3    Feature_4    0.632636\n",
      "14  Feature_15    0.623380\n",
      "6    Feature_7    0.611160\n",
      "2    Feature_3    0.611056\n",
      "11  Feature_12    0.605774\n",
      "21  Feature_22    0.605305\n",
      "15  Feature_16    0.583139\n",
      "20  Feature_21    0.578708\n",
      "5    Feature_6    0.525591\n",
      "12  Feature_13    0.525016\n",
      "22  Feature_23    0.513191\n",
      "8    Feature_9    0.498446\n",
      "7    Feature_8    0.445523\n",
      "10  Feature_11    0.426728\n",
      "13  Feature_14    0.412976\n",
      "19  Feature_20    0.411979\n",
      "23  Feature_24    0.403025\n",
      "4    Feature_5    0.357742\n",
      "0    Feature_1    0.295452\n",
      "9   Feature_10    0.282031\n",
      "41  Feature_42    0.271026\n",
      "31  Feature_32    0.269761\n",
      "35  Feature_36    0.235192\n",
      "42  Feature_43    0.233616\n",
      "37  Feature_38    0.233302\n",
      "30  Feature_31    0.223217\n",
      "26  Feature_27    0.218514\n",
      "45  Feature_46    0.216297\n",
      "49  Feature_50    0.210926\n",
      "33  Feature_34    0.198746\n",
      "27  Feature_28    0.182124\n",
      "32  Feature_33    0.176726\n",
      "47  Feature_48    0.173114\n",
      "44  Feature_45    0.156246\n",
      "48  Feature_49    0.142491\n",
      "43  Feature_44    0.121773\n",
      "38  Feature_39    0.111998\n",
      "46  Feature_47    0.111559\n",
      "34  Feature_35    0.110308\n",
      "28  Feature_29    0.108916\n",
      "29  Feature_30    0.107056\n",
      "40  Feature_41    0.091220\n",
      "39  Feature_40    0.084028\n",
      "36  Feature_37    0.082141\n",
      "25  Feature_26    0.054573\n"
     ]
    }
   ],
   "source": [
    "from minepy import MINE\n",
    "import numpy as np\n",
    "\n",
    "mine = MINE()\n",
    "\n",
    "mic_scores = np.zeros((X.shape[1], y.shape[1]))  \n",
    "\n",
    "for i, feature in enumerate(X.columns):\n",
    "    for j, output in enumerate(y.columns):\n",
    "        mine.compute_score(X[feature].values, y[output].values)\n",
    "        mic_scores[i, j] = mine.mic()\n",
    "\n",
    "average_mic_scores = mic_scores.mean(axis=1)\n",
    "\n",
    "feature_mic_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Average_MIC': average_mic_scores\n",
    "}).sort_values(by='Average_MIC', ascending=False)\n",
    "\n",
    "print(feature_mic_df)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Create an array to store mutual information scores for each feature-output pair\n",
    "mi_scores = np.zeros((X.shape[1], y.shape[1]))\n",
    "\n",
    "# Calculate mutual information for each feature against each output\n",
    "for i, output in enumerate(y.columns):\n",
    "    mi_scores[:, i] = mutual_info_regression(X, y[output].values, random_state=42)\n",
    "\n",
    "# Compute average mutual information for each feature across all outputs\n",
    "average_mi_scores = mi_scores.mean(axis=1)\n",
    "\n",
    "# Create a DataFrame to display features and their average mutual information scores\n",
    "feature_mi_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Average_MI': average_mi_scores\n",
    "}).sort_values(by='Average_MI', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(feature_mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a6bc8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature         VIF\n",
      "3    Feature_4  542.727007\n",
      "14  Feature_15  435.237497\n",
      "24  Feature_25  380.905803\n",
      "18  Feature_19  345.627178\n",
      "11  Feature_12  199.864219\n",
      "15  Feature_16  124.632794\n",
      "17  Feature_18  100.608891\n",
      "21  Feature_22  100.274209\n",
      "1    Feature_2   89.696554\n",
      "16  Feature_17   32.108044\n",
      "2    Feature_3   31.222708\n",
      "20  Feature_21   29.374241\n",
      "13  Feature_14   26.674050\n",
      "19  Feature_20   25.932147\n",
      "5    Feature_6   23.105097\n",
      "4    Feature_5   22.829768\n",
      "12  Feature_13   21.328415\n",
      "6    Feature_7   21.187889\n",
      "8    Feature_9   21.083165\n",
      "7    Feature_8   20.286845\n",
      "9   Feature_10   19.362424\n",
      "23  Feature_24   15.799666\n",
      "0    Feature_1   13.682924\n",
      "10  Feature_11   13.529012\n",
      "22  Feature_23   13.323548\n",
      "30  Feature_31    9.244250\n",
      "32  Feature_33    8.942437\n",
      "37  Feature_38    8.867152\n",
      "48  Feature_49    8.773365\n",
      "38  Feature_39    8.739385\n",
      "25  Feature_26    8.605336\n",
      "31  Feature_32    8.335603\n",
      "27  Feature_28    8.210832\n",
      "47  Feature_48    8.103190\n",
      "45  Feature_46    8.038583\n",
      "46  Feature_47    8.016604\n",
      "35  Feature_36    7.987013\n",
      "26  Feature_27    7.760970\n",
      "33  Feature_34    7.751277\n",
      "42  Feature_43    7.714726\n",
      "40  Feature_41    7.655808\n",
      "44  Feature_45    7.546718\n",
      "43  Feature_44    7.513531\n",
      "29  Feature_30    7.484827\n",
      "41  Feature_42    7.292844\n",
      "34  Feature_35    7.290698\n",
      "49  Feature_50    6.650378\n",
      "36  Feature_37    6.487528\n",
      "28  Feature_29    5.458421\n",
      "39  Feature_40    4.407242\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12b9531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features to remove due to high VIF (>= 10): ['Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22', 'Feature_25']\n",
      "\n",
      "Iteration 1: Removing features ['Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22', 'Feature_25']\n",
      "\n",
      "Features to remove due to high VIF (>= 10): []\n",
      "\n",
      "Final feature set after VIF filtering:\n",
      "['Feature_1', 'Feature_10', 'Feature_11', 'Feature_23', 'Feature_24', 'Feature_26', 'Feature_27', 'Feature_28', 'Feature_29', 'Feature_30', 'Feature_31', 'Feature_32', 'Feature_33', 'Feature_34', 'Feature_35', 'Feature_36', 'Feature_37', 'Feature_38', 'Feature_39', 'Feature_40', 'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45', 'Feature_46', 'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate VIF and identify high VIF features\n",
    "def calculate_vif(data, threshold=20):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = data.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    \n",
    "    # Identify features to remove\n",
    "    high_vif_features = vif_data[vif_data[\"VIF\"] >= threshold][\"Feature\"].tolist()\n",
    "    \n",
    "    print(\"\\nFeatures to remove due to high VIF (>= 10):\", high_vif_features)\n",
    "    \n",
    "    return high_vif_features\n",
    "X_t = X\n",
    "# Initial calculation\n",
    "features_to_remove = calculate_vif(X_t)\n",
    "\n",
    "# Iteratively remove features with high VIF\n",
    "iteration = 1\n",
    "while features_to_remove:\n",
    "    print(f\"\\nIteration {iteration}: Removing features {features_to_remove}\")\n",
    "    X_t = X_t.drop(columns=features_to_remove)\n",
    "    features_to_remove = calculate_vif(X_t)\n",
    "    iteration += 1\n",
    "\n",
    "print(\"\\nFinal feature set after VIF filtering:\")\n",
    "print(X_t.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04c6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[X_t.columns]\n",
    "X_val = X_val[X_t.columns]\n",
    "X_test = X_test[X_t.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d40b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE for each output: [0.00095248 0.00029309 0.00271742 0.00103777 0.00143985]\n",
      "XGBoost Validation MSE: [0.0009246  0.00030657 0.00237065 0.00074768 0.00166186]\n",
      "CatBoost Validation MSE: [0.00060637 0.00013584 0.00234464 0.00101009 0.00127334]\n"
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "rval_mse = mean_squared_error(y_val, y_val_pred, multioutput='raw_values')\n",
    "print(\"Validation MSE for each output:\", val_mse)\n",
    "xgb_model = MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "rxgb_val_mse = mean_squared_error(y_val, xgb_val_pred, multioutput='raw_values')\n",
    "\n",
    "print(\"XGBoost Validation MSE:\", xgb_val_mse)\n",
    "\n",
    "# CatBoost model\n",
    "catboost_model = MultiOutputRegressor(CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1, loss_function='MultiRMSE', random_seed=42, verbose=0))\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_val_pred = catboost_model.predict(X_val)\n",
    "rcatboost_val_mse = mean_squared_error(y_val, catboost_val_pred, multioutput='raw_values')\n",
    "\n",
    "print(\"CatBoost Validation MSE:\", catboost_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a46bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Random Forest MSE: [0.00095248 0.00029309 0.00271742 0.00103777 0.00143985]\n",
      "Reduced Random Forest MSE: [0.00586379 0.00076431 0.01577159 0.01817172 0.00391532]\n",
      "Original XGBoost MSE: [0.0009246  0.00030657 0.00237065 0.00074768 0.00166186]\n",
      "Reduced XGBoost MSE: [0.00538631 0.00064996 0.0136334  0.01355023 0.00359942]\n",
      "Original CatBoost MSE: [0.00060637 0.00013584 0.00234464 0.00101009 0.00127334]\n",
      "Reduced CatBoost MSE: [0.00485484 0.00057191 0.01386341 0.01742942 0.0031749 ]\n",
      "Random Forest MSE Percentage Change: [ 515.63364866  160.77266968  480.38921364 1651.0293614   171.92559532]\n",
      "XGBoost MSE Percentage Change: [ 482.55736215  112.01257144  475.0911623  1712.29559959  116.58977708]\n",
      "CatBoost MSE Percentage Change: [ 700.63334143  321.032833    491.28092806 1625.5385369   149.33621415]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Random Forest MSE:\", val_mse)\n",
    "print(\"Reduced Random Forest MSE:\", rval_mse)\n",
    "\n",
    "print(\"Original XGBoost MSE:\", xgb_val_mse)\n",
    "print(\"Reduced XGBoost MSE:\", rxgb_val_mse)\n",
    "\n",
    "print(\"Original CatBoost MSE:\", catboost_val_mse)\n",
    "print(\"Reduced CatBoost MSE:\", rcatboost_val_mse)\n",
    "\n",
    "\n",
    "\n",
    "# Percentage change calculations\n",
    "rf_percentage_change = (rval_mse - val_mse) / val_mse * 100\n",
    "xgb_percentage_change = (rxgb_val_mse  - xgb_val_mse ) / xgb_val_mse  * 100\n",
    "catboost_percentage_change = (rcatboost_val_mse - catboost_val_mse) / catboost_val_mse * 100\n",
    "\n",
    "# Display the results\n",
    "print(\"Random Forest MSE Percentage Change:\", rf_percentage_change)\n",
    "print(\"XGBoost MSE Percentage Change:\", xgb_percentage_change)\n",
    "print(\"CatBoost MSE Percentage Change:\", catboost_percentage_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35d5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d939a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Feature_12', 'Feature_13', 'Feature_18', 'Feature_25'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use RFECV with a non-linear model (e.g., RandomForest)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "selector = RFECV(estimator=model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[selector.support_]\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c627c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features with Linear Regression: Index(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5',\n",
      "       'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10',\n",
      "       'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15',\n",
      "       'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20', 'Feature_22',\n",
      "       'Feature_23', 'Feature_25', 'Feature_26', 'Feature_27', 'Feature_28',\n",
      "       'Feature_29', 'Feature_30', 'Feature_31', 'Feature_32', 'Feature_33',\n",
      "       'Feature_34', 'Feature_35', 'Feature_36', 'Feature_37', 'Feature_39',\n",
      "       'Feature_40', 'Feature_41', 'Feature_42', 'Feature_44', 'Feature_45',\n",
      "       'Feature_46', 'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50'],\n",
      "      dtype='object')\n",
      "Selected features with Random Forest: Index(['Feature_2', 'Feature_3', 'Feature_4', 'Feature_6', 'Feature_7',\n",
      "       'Feature_12', 'Feature_13', 'Feature_15', 'Feature_17', 'Feature_18',\n",
      "       'Feature_19', 'Feature_20', 'Feature_22', 'Feature_25', 'Feature_32',\n",
      "       'Feature_37', 'Feature_45'],\n",
      "      dtype='object')\n",
      "Linear Regression Validation MSE with selected features: 0.005164450696565827\n",
      "Random Forest Validation MSE with selected features: 0.0013061079129489447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear model example\n",
    "linear_model = LinearRegression()\n",
    "rfecv_linear = RFECV(estimator=linear_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv_linear.fit(X_train, y_train)\n",
    "selected_features_linear = X.columns[rfecv_linear.support_]\n",
    "print(\"Selected features with Linear Regression:\", selected_features_linear)\n",
    "\n",
    "# Non-linear model example (e.g., Random Forest)\n",
    "non_linear_model = RandomForestRegressor(random_state=42)\n",
    "rfecv_non_linear = RFECV(estimator=non_linear_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv_non_linear.fit(X_train, y_train)\n",
    "selected_features_non_linear = X.columns[rfecv_non_linear.support_]\n",
    "print(\"Selected features with Random Forest:\", selected_features_non_linear)\n",
    "\n",
    "# Evaluate each model with the selected features\n",
    "X_train_linear = X_train[selected_features_linear]\n",
    "X_val_linear = X_val[selected_features_linear]\n",
    "linear_model.fit(X_train_linear, y_train)\n",
    "linear_val_pred = linear_model.predict(X_val_linear)\n",
    "linear_val_mse = mean_squared_error(y_val, linear_val_pred)\n",
    "print(\"Linear Regression Validation MSE with selected features:\", linear_val_mse)\n",
    "\n",
    "X_train_rf = X_train[selected_features_non_linear]\n",
    "X_val_rf = X_val[selected_features_non_linear]\n",
    "non_linear_model.fit(X_train_rf, y_train)\n",
    "rf_val_pred = non_linear_model.predict(X_val_rf)\n",
    "rf_val_mse = mean_squared_error(y_val, rf_val_pred)\n",
    "print(\"Random Forest Validation MSE with selected features:\", rf_val_mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cecb04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Validation MSE with selected MIC features: 0.0063204933168285295\n",
      "Polynomial Regression Validation MSE with selected MIC features: 0.0024478580096430618\n",
      "Gradient Boosting Validation MSE with selected MIC features: 0.0011755406941782855\n",
      "Random Forest Validation MSE with selected MIC features: 0.0012124787268030092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# List of selected features based on provided MIC scores\n",
    "selected_features_mic = [\n",
    "    'Feature_18', 'Feature_2', 'Feature_19', 'Feature_25', 'Feature_17',\n",
    "    'Feature_15', 'Feature_4', 'Feature_12', 'Feature_7', 'Feature_3',\n",
    "    'Feature_16', 'Feature_13', 'Feature_22', 'Feature_6', 'Feature_20', 'Feature_9', 'Feature_21'\n",
    "]\n",
    "\n",
    "# Subset X_train and X_val using the selected features\n",
    "X_train_mic = X_train[selected_features_mic]\n",
    "X_val_mic = X_val[selected_features_mic]\n",
    "# Fit and evaluate a Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_mic, y_train)\n",
    "linear_val_pred_mic = linear_model.predict(X_val_mic)\n",
    "linear_val_mse_mic = mean_squared_error(y_val, linear_val_pred_mic)\n",
    "print(\"Linear Regression Validation MSE with selected MIC features:\", linear_val_mse_mic)\n",
    "\n",
    "# Fit and evaluate a Polynomial Regression model (degree 2 as an example)\n",
    "poly_pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "poly_pipeline.fit(X_train_mic, y_train)\n",
    "poly_val_pred_mic = poly_pipeline.predict(X_val_mic)\n",
    "poly_val_mse_mic = mean_squared_error(y_val, poly_val_pred_mic)\n",
    "print(\"Polynomial Regression Validation MSE with selected MIC features:\", poly_val_mse_mic)\n",
    "\n",
    "# Fit and evaluate a multi-output Gradient Boosting model\n",
    "gb_model = MultiOutputRegressor(GradientBoostingRegressor())\n",
    "gb_model.fit(X_train_mic, y_train)\n",
    "gb_val_pred_mic = gb_model.predict(X_val_mic)\n",
    "gb_val_mse_mic = mean_squared_error(y_val, gb_val_pred_mic, multioutput='uniform_average')  # Calculate MSE for multi-output\n",
    "print(\"Gradient Boosting Validation MSE with selected MIC features:\", gb_val_mse_mic)\n",
    "\n",
    " # Fit and evaluate a multi-output Random Forest model\n",
    "rf_model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "rf_model.fit(X_train_mic, y_train)\n",
    "rf_val_pred_mic = rf_model.predict(X_val_mic)\n",
    "rf_val_mse_mic = mean_squared_error(y_val, rf_val_pred_mic, multioutput='uniform_average')\n",
    "print(\"Random Forest Validation MSE with selected MIC features:\", rf_val_mse_mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e11a218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.38461916252641"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_val_mse - linear_val_mse_mic)/linear_val_mse*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a45e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3770130724894543"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rf_val_mse - overall_val_mse)/rf_val_mse *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceea136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.291455594997154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rf_val_mse_mic - overall_val_mse)/rf_val_mse_mic *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91064b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features with XGBoost: Index(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5',\n",
      "       'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10',\n",
      "       'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15',\n",
      "       'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20',\n",
      "       'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24', 'Feature_25',\n",
      "       'Feature_27', 'Feature_28', 'Feature_30', 'Feature_31', 'Feature_32',\n",
      "       'Feature_33', 'Feature_35', 'Feature_37', 'Feature_38', 'Feature_39',\n",
      "       'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45',\n",
      "       'Feature_46', 'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50'],\n",
      "      dtype='object')\n",
      "XGBoost Validation MSE with selected features: 0.0010523892377625604\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model for feature selection\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "rfecv_xgb = RFECV(estimator=xgb_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_xgb = X.columns[rfecv_xgb.support_]\n",
    "print(\"Selected features with XGBoost:\", selected_features_xgb)\n",
    "\n",
    "# Evaluate XGBoost with selected features\n",
    "X_train_xgb = X_train[selected_features_xgb]\n",
    "X_val_xgb = X_val[selected_features_xgb]\n",
    "xgb_model.fit(X_train_xgb, y_train)\n",
    "xgb_val_pred = xgb_model.predict(X_val_xgb)\n",
    "xgb_val_mse = mean_squared_error(y_val, xgb_val_pred)\n",
    "print(\"XGBoost Validation MSE with selected features:\", xgb_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37845019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.242103499059663"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgb_val_mse - overall_val_xgb)/xgb_val_mse *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dcde745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features with CatBoost for the first output: Index(['Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6',\n",
      "       'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_12',\n",
      "       'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17',\n",
      "       'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22',\n",
      "       'Feature_23', 'Feature_24', 'Feature_25', 'Feature_26', 'Feature_27',\n",
      "       'Feature_28', 'Feature_30', 'Feature_31', 'Feature_34', 'Feature_36',\n",
      "       'Feature_38', 'Feature_39', 'Feature_40', 'Feature_41', 'Feature_43',\n",
      "       'Feature_44', 'Feature_45', 'Feature_46', 'Feature_48', 'Feature_49'],\n",
      "      dtype='object')\n",
      "CatBoost Validation MSE with selected features: 0.0008618230780961363\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use CatBoostRegressor directly for feature selection\n",
    "catboost_model = CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1, loss_function='RMSE', random_seed=42, verbose=0)\n",
    "\n",
    "# Perform RFECV on a single target column (e.g., the first output)\n",
    "rfecv_catboost = RFECV(estimator=catboost_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv_catboost.fit(X_train, y_train.iloc[:, 0])  # You can loop over y_train columns if needed\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_catboost = X_train.columns[rfecv_catboost.support_]\n",
    "print(\"Selected features with CatBoost for the first output:\", selected_features_catboost)\n",
    "\n",
    "# Train MultiOutputRegressor with the selected features\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "multi_catboost_model = MultiOutputRegressor(CatBoostRegressor(iterations=500, depth=6, learning_rate=0.1, loss_function='RMSE', random_seed=42, verbose=0))\n",
    "X_train_selected = X_train[selected_features_catboost]\n",
    "X_val_selected = X_val[selected_features_catboost]\n",
    "\n",
    "multi_catboost_model.fit(X_train_selected, y_train)\n",
    "catboost_val_pred = multi_catboost_model.predict(X_val_selected)\n",
    "\n",
    "# Calculate MSE\n",
    "catboost_val_mse = mean_squared_error(y_val, catboost_val_pred)\n",
    "print(\"CatBoost Validation MSE with selected features:\", catboost_val_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f26fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor Validation MSE: [0.00113875 0.00046317 0.00285362 0.00195846 0.00351331]\n",
      "Overall Validation MSE: 0.0019854614211898885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# MLP model\n",
    "mlp_model = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "mlp_val_pred = mlp_model.predict(X_val)\n",
    "mlp_val_mse = mean_squared_error(y_val, mlp_val_pred, multioutput='raw_values')\n",
    "print(\"MLP Regressor Validation MSE:\", mlp_val_mse)\n",
    "overall_val_mlp = mean_squared_error(y_val, mlp_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e256ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Validation MSE: [0.00049871 0.00014605 0.0019072  0.00089673 0.00097978]\n",
      "Overall Validation MSE: 0.0008856931577206666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Gradient Boosting model\n",
    "gbr_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "gbr_val_pred = gbr_model.predict(X_val)\n",
    "gbr_val_mse = mean_squared_error(y_val, gbr_val_pred, multioutput='raw_values')\n",
    "print(\"Gradient Boosting Regressor Validation MSE:\", gbr_val_mse)\n",
    "overall_val_gbr = mean_squared_error(y_val, gbr_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_gbr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "153f5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing RFECV for output 1...\n",
      "Selected features for output 1: Index(['Feature_2', 'Feature_4', 'Feature_5', 'Feature_7', 'Feature_8',\n",
      "       'Feature_12', 'Feature_13', 'Feature_15', 'Feature_16', 'Feature_17',\n",
      "       'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22',\n",
      "       'Feature_24', 'Feature_25', 'Feature_26', 'Feature_27', 'Feature_30',\n",
      "       'Feature_39', 'Feature_49'],\n",
      "      dtype='object')\n",
      "Performing RFECV for output 2...\n",
      "Selected features for output 2: Index(['Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6',\n",
      "       'Feature_7', 'Feature_8', 'Feature_9', 'Feature_11', 'Feature_12',\n",
      "       'Feature_13', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18',\n",
      "       'Feature_20', 'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24',\n",
      "       'Feature_25', 'Feature_28', 'Feature_30', 'Feature_31', 'Feature_32',\n",
      "       'Feature_33', 'Feature_34'],\n",
      "      dtype='object')\n",
      "Performing RFECV for output 3...\n",
      "Selected features for output 3: Index(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_8', 'Feature_11',\n",
      "       'Feature_12', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17',\n",
      "       'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22',\n",
      "       'Feature_23', 'Feature_24', 'Feature_25', 'Feature_31', 'Feature_32',\n",
      "       'Feature_37', 'Feature_39', 'Feature_41', 'Feature_42', 'Feature_45',\n",
      "       'Feature_46', 'Feature_47', 'Feature_48', 'Feature_49'],\n",
      "      dtype='object')\n",
      "Performing RFECV for output 4...\n",
      "Selected features for output 4: Index(['Feature_1', 'Feature_2', 'Feature_4', 'Feature_5', 'Feature_6',\n",
      "       'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11',\n",
      "       'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16',\n",
      "       'Feature_17', 'Feature_18', 'Feature_19', 'Feature_21', 'Feature_22',\n",
      "       'Feature_23', 'Feature_24', 'Feature_25', 'Feature_26', 'Feature_27',\n",
      "       'Feature_28', 'Feature_29', 'Feature_30', 'Feature_31', 'Feature_33',\n",
      "       'Feature_34', 'Feature_35', 'Feature_36', 'Feature_37', 'Feature_38',\n",
      "       'Feature_39', 'Feature_40', 'Feature_41', 'Feature_42', 'Feature_43',\n",
      "       'Feature_44', 'Feature_45', 'Feature_46', 'Feature_47', 'Feature_48',\n",
      "       'Feature_49', 'Feature_50'],\n",
      "      dtype='object')\n",
      "Performing RFECV for output 5...\n",
      "Selected features for output 5: Index(['Feature_2', 'Feature_7', 'Feature_11', 'Feature_12', 'Feature_15',\n",
      "       'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20',\n",
      "       'Feature_21', 'Feature_22', 'Feature_25', 'Feature_35', 'Feature_50'],\n",
      "      dtype='object')\n",
      "Union of selected features across all outputs: {'Feature_36', 'Feature_17', 'Feature_23', 'Feature_21', 'Feature_28', 'Feature_16', 'Feature_25', 'Feature_7', 'Feature_26', 'Feature_10', 'Feature_5', 'Feature_13', 'Feature_46', 'Feature_41', 'Feature_9', 'Feature_29', 'Feature_38', 'Feature_50', 'Feature_43', 'Feature_40', 'Feature_30', 'Feature_31', 'Feature_45', 'Feature_34', 'Feature_35', 'Feature_42', 'Feature_1', 'Feature_18', 'Feature_39', 'Feature_19', 'Feature_47', 'Feature_32', 'Feature_37', 'Feature_49', 'Feature_33', 'Feature_4', 'Feature_12', 'Feature_44', 'Feature_2', 'Feature_24', 'Feature_22', 'Feature_11', 'Feature_8', 'Feature_20', 'Feature_27', 'Feature_14', 'Feature_3', 'Feature_48', 'Feature_6', 'Feature_15'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1k/3_n7gml123ngyj64bxhm6zgr0000gn/T/ipykernel_81199/1880108740.py:27: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_train_selected = X_train[common_selected_features]\n",
      "/var/folders/1k/3_n7gml123ngyj64bxhm6zgr0000gn/T/ipykernel_81199/1880108740.py:28: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  X_val_selected = X_val[common_selected_features]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Validation MSE with selected features: [0.00048577 0.000146   0.00185107 0.0009392  0.00103691]\n",
      "Overall Validation MSE: 0.0008917877079670684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Store selected features for each output\n",
    "selected_features_per_output = []\n",
    "\n",
    "# Perform RFECV for each output individually\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Performing RFECV for output {i + 1}...\")\n",
    "    gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "    rfecv_gbr = RFECV(estimator=gbr_model, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "    rfecv_gbr.fit(X_train, y_train.iloc[:, i])\n",
    "    \n",
    "    selected_features = X_train.columns[rfecv_gbr.support_]\n",
    "    selected_features_per_output.append(selected_features)\n",
    "    print(f\"Selected features for output {i + 1}: {selected_features}\")\n",
    "\n",
    "# Find the union of selected features across all outputs\n",
    "common_selected_features = set().union(*selected_features_per_output)\n",
    "print(\"Union of selected features across all outputs:\", common_selected_features)\n",
    "\n",
    "# Train a MultiOutputRegressor with Gradient Boosting on the selected features\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train_selected = X_train[common_selected_features]\n",
    "X_val_selected = X_val[common_selected_features]\n",
    "\n",
    "multi_gbr_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "multi_gbr_model.fit(X_train_selected, y_train)\n",
    "gbr_val_pred = multi_gbr_model.predict(X_val_selected)\n",
    "\n",
    "# Calculate the MSE\n",
    "gbr_val_mse = mean_squared_error(y_val, gbr_val_pred, multioutput='raw_values')\n",
    "print(\"Gradient Boosting Regressor Validation MSE with selected features:\", gbr_val_mse)\n",
    "overall_val_gbr = mean_squared_error(y_val, gbr_val_pred)\n",
    "print(\"Overall Validation MSE:\", overall_val_gbr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31ff7035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor Validation MSE: [0.00067552 0.00043519 0.00157265 0.00141907 0.00097944]\n",
      "Overall KNN Validation MSE: 0.0010163747809966719\n",
      "SVR Regressor Validation MSE: [0.00249404 0.00280899 0.00542869 0.00389307 0.0043833 ]\n",
      "Overall SVR Validation MSE: 0.0038016219406753838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# KNN model\n",
    "knn_model = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=5))\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set with KNN\n",
    "knn_val_pred = knn_model.predict(X_val)\n",
    "knn_val_mse = mean_squared_error(y_val, knn_val_pred, multioutput='raw_values')\n",
    "print(\"KNN Regressor Validation MSE:\", knn_val_mse)\n",
    "overall_val_knn = mean_squared_error(y_val, knn_val_pred)\n",
    "print(\"Overall KNN Validation MSE:\", overall_val_knn)\n",
    "\n",
    "# SVR model\n",
    "svr_model = MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set with SVR\n",
    "svr_val_pred = svr_model.predict(X_val)\n",
    "svr_val_mse = mean_squared_error(y_val, svr_val_pred, multioutput='raw_values')\n",
    "print(\"SVR Regressor Validation MSE:\", svr_val_mse)\n",
    "overall_val_svr = mean_squared_error(y_val, svr_val_pred)\n",
    "print(\"Overall SVR Validation MSE:\", overall_val_svr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "650e0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Validation MSE with selected features: 0.003769825845962759\n"
     ]
    }
   ],
   "source": [
    "# Subset the training and validation sets with the selected features\n",
    "X_train_selected = X_train[selected_features_catboost]\n",
    "X_val_selected = X_val[selected_features_catboost]\n",
    "\n",
    "# Train SVR with the selected features\n",
    "svr_model = MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "svr_model.fit(X_train_selected, y_train)\n",
    "svr_val_pred = svr_model.predict(X_val_selected)\n",
    "svr_val_mse = mean_squared_error(y_val, svr_val_pred)\n",
    "print(\"SVR Validation MSE with selected features:\", svr_val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816515d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
